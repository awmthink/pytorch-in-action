{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchScript\n",
    "\n",
    "TorchScript is an intermediate representation of a PyTorch model (subclass of nn.Module) that can then be run in a high-performance environment such as C++.\n",
    "\n",
    "TorchScript从Pytorch 1.0开始引入，它是一种新的progamming model，是Python语言的一个子集，能够被TorchScript的编译器进行解析、编译和优化。编译过后的torchscript可以被序列化成文件，随后被C++的pytorch backend加载执行。\n",
    "\n",
    "TorchSript能够支持torch包中的大量的operations，我们可以把torch理解为torchscript这个语言的标准库，使用这个标准库中的Tensor操作组成的一系列运算都能被TorchScript的编译器编译。同时，我们也会存在实现一些特殊算子的需求，我们可以使用C++/CUDA来扩展算子，这些算子基于ATen来实现，它们能够被TorchScript编译，进而其序列文件可以被Python或C++来加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Pytorch NN Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class MyDecisionGate(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x.sum() > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "\n",
    "\n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self, dg=None):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.dg = dg\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        if self.dg is None:\n",
    "            new_h = torch.tanh(self.linear(x) + h)\n",
    "        else:\n",
    "            new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell(\n",
      "  (linear): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n",
      "(tensor([[ 0.4873,  0.9206, -0.6983, -0.6580],\n",
      "        [-0.9721,  0.7046,  0.2144, -0.9662],\n",
      "        [-0.0251,  0.6369,  0.9375, -0.3248]], grad_fn=<TanhBackward0>), tensor([[ 0.4873,  0.9206, -0.6983, -0.6580],\n",
      "        [-0.9721,  0.7046,  0.2144, -0.9662],\n",
      "        [-0.0251,  0.6369,  0.9375, -0.3248]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "cell = MyCell()\n",
    "x = torch.randn(3, 4)\n",
    "h = torch.randn(3, 4)\n",
    "\n",
    "print(cell)\n",
    "print(cell(x, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracing Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell(\n",
      "  original_name=MyCell\n",
      "  (linear): Linear(original_name=Linear)\n",
      ")\n",
      "(tensor([[ 0.4873,  0.9206, -0.6983, -0.6580],\n",
      "        [-0.9721,  0.7046,  0.2144, -0.9662],\n",
      "        [-0.0251,  0.6369,  0.9375, -0.3248]], grad_fn=<TanhBackward0>), tensor([[ 0.4873,  0.9206, -0.6983, -0.6580],\n",
      "        [-0.9721,  0.7046,  0.2144, -0.9662],\n",
      "        [-0.0251,  0.6369,  0.9375, -0.3248]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "traced_cell = torch.jit.trace(cell, (x, h))\n",
    "print(traced_cell)\n",
    "print(traced_cell(x, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What exactly has this done? It has invoked the Module, recorded the operations that occurred when the Module was run, and created an instance of torch.jit.ScriptModule (of which TracedModule is an instance)\n",
    "\n",
    "TorchScript records its definitions in an Intermediate Representation (or IR), commonly referred to in Deep learning as a graph. We can examine the graph with the .graph property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self.1 : __torch__.MyCell,\n",
      "      %x : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu),\n",
      "      %h : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu)):\n",
      "  %linear : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear\"](%self.1)\n",
      "  %20 : Tensor = prim::CallMethod[name=\"forward\"](%linear, %x)\n",
      "  %11 : int = prim::Constant[value=1]() # /tmp/ipykernel_267643/808754513.py:20:0\n",
      "  %12 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::add(%20, %h, %11) # /tmp/ipykernel_267643/808754513.py:20:0\n",
      "  %13 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::tanh(%12) # /tmp/ipykernel_267643/808754513.py:20:0\n",
      "  %14 : (Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu), Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu)) = prim::TupleConstruct(%13, %13)\n",
      "  return (%14)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traced_cell.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is a very low-level representation and most of the information contained in the graph is not useful for end users. Instead, we can use the .code property to give a Python-syntax interpretation of the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  linear = self.linear\n",
      "  _0 = torch.tanh(torch.add((linear).forward(x, ), h))\n",
      "  return (_0, _0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why use trace module\n",
    "\n",
    "* TorchScript code can be invoked in its own interpreter, which is basically a restricted Python interpreter. This interpreter does not acquire the Global Interpreter Lock, and so many requests can be processed on the same instance simultaneously.\n",
    "* This format allows us to save the whole model to disk and load it into another environment, such as in a server written in a language other than Python\n",
    "* TorchScript gives us a representation in which we can do compiler optimizations on the code to provide more efficient execution\n",
    "* TorchScript allows us to inference with many backend/device runtimes that require a broader view of the program than individual operators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uing Scripting to Convert Modules\n",
    "\n",
    "## Tracing Module存在的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    argument_1: Tensor) -> NoneType:\n",
      "  return None\n",
      "\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = (linear).forward(x, )\n",
      "  _1 = (dg).forward(_0, )\n",
      "  _2 = torch.tanh(torch.add(_0, h))\n",
      "  return (_2, _2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_267643/808754513.py:6: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if x.sum() > 0:\n"
     ]
    }
   ],
   "source": [
    "cell = MyCell(MyDecisionGate())\n",
    "traced_cell = torch.jit.trace(cell, (x, h))\n",
    "# MyDecisionGate编译出来的code里，直接返回了 torch.neg(argument_1)\n",
    "print(traced_cell.dg.code)\n",
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the .code output, we can see that the if-else branch is nowhere to be found! Why? Tracing does exactly what we said it would: run the code, record the operations that happen and construct a ScriptModule that does exactly that. Unfortunately, things like control flow are erased.\n",
    "\n",
    "Tracing只是精确的记录：在编译模型时，给定的输入时，整个代码的执行的过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script Compiler\n",
    "\n",
    "script compiler 并不像 tracking那样记录整个Tensor的执行过程，而是像其他语言编译器一样，直接分析源代码，不需要模拟计算。\n",
    "\n",
    "How can we faithfully represent this module in TorchScript? We provide a script compiler, which does direct analysis of your Python source code to transform it into TorchScript. Let’s convert MyDecisionGate using the script compiler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  if bool(torch.gt(torch.sum(x), 0)):\n",
      "    _0 = x\n",
      "  else:\n",
      "    _0 = torch.neg(x)\n",
      "  return _0\n",
      "\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n",
      "  new_h = torch.tanh(_0)\n",
      "  return (new_h, new_h)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scripted_cell = torch.jit.script(cell)\n",
    "print(scripted_cell.dg.code)\n",
    "print(scripted_cell.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixing Scripting and Tracing\n",
    "\n",
    "Some situations call for using tracing rather than scripting (e.g. a module has many architectural decisions that are made based on constant Python values that we would like to not appear in TorchScript). In this case, scripting can be composed with tracing: `torch.jit.script` will inline the code for a traced module, and tracing will inline the code for a scripted module.\n",
    "\n",
    "我们可以把代码中存在分支条件的部分，先用jit.script来编译；然后再在整个执行上使用jit.trace来转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn loop: \n",
      "def forward(self,\n",
      "    xs: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  h = torch.zeros([3, 4])\n",
      "  y = torch.zeros([3, 4])\n",
      "  y0 = y\n",
      "  h0 = h\n",
      "  for i in range(torch.size(xs, 0)):\n",
      "    cell = self.cell\n",
      "    _0 = (cell).forward(torch.select(xs, 0, i), h0, )\n",
      "    y1, h1, = _0\n",
      "    y0, h0 = y1, h1\n",
      "  return (y0, h0)\n",
      "\n",
      "rnn loop cell: \n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n",
      "  _1 = torch.tanh(_0)\n",
      "  return (_1, _1)\n",
      "\n",
      "rnn loop cell dg: \n",
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  if bool(torch.gt(torch.sum(x), 0)):\n",
      "    _0 = x\n",
      "  else:\n",
      "    _0 = torch.neg(x)\n",
      "  return _0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class MyRNNLoop(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyRNNLoop, self).__init__()\n",
    "        self.cell = torch.jit.trace(MyCell(scripted_cell.dg), (x, h))\n",
    "\n",
    "    def forward(self, xs):\n",
    "        h, y = torch.zeros(3, 4), torch.zeros(3, 4)\n",
    "        for i in range(xs.size(0)):\n",
    "            y, h = self.cell(xs[i], h)\n",
    "        return y, h\n",
    "\n",
    "\n",
    "# dg是jit.script的\n",
    "# cell是git.trace的\n",
    "# rnn_loop是jit.script的\n",
    "rnn_loop = torch.jit.script(MyRNNLoop())\n",
    "print(\"rnn loop: \")\n",
    "print(rnn_loop.code)\n",
    "print(\"rnn loop cell: \")\n",
    "print(rnn_loop.cell.code)\n",
    "print(\"rnn loop cell dg: \")\n",
    "print(rnn_loop.cell.dg.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And an example of the second case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    xs: Tensor) -> Tensor:\n",
      "  loop = self.loop\n",
      "  _0, y, = (loop).forward(xs, )\n",
      "  return torch.relu(y)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class WrapRNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WrapRNN, self).__init__()\n",
    "        self.loop = torch.jit.script(MyRNNLoop())\n",
    "\n",
    "    def forward(self, xs):\n",
    "        y, h = self.loop(xs)\n",
    "        return torch.relu(y)\n",
    "\n",
    "\n",
    "traced = torch.jit.trace(WrapRNN(), (torch.rand(10, 3, 4)))\n",
    "print(traced.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(\n",
      "  original_name=WrapRNN\n",
      "  (loop): RecursiveScriptModule(\n",
      "    original_name=MyRNNLoop\n",
      "    (cell): RecursiveScriptModule(\n",
      "      original_name=MyCell\n",
      "      (dg): RecursiveScriptModule(original_name=MyDecisionGate)\n",
      "      (linear): RecursiveScriptModule(original_name=Linear)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "def forward(self,\n",
      "    xs: Tensor) -> Tensor:\n",
      "  loop = self.loop\n",
      "  _0, y, = (loop).forward(xs, )\n",
      "  return torch.relu(y)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "traced.save(\"/tmp/wrapped_rnn.pt\")\n",
    "loaded = torch.jit.load(\"/tmp/wrapped_rnn.pt\")\n",
    "print(loaded)\n",
    "print(loaded.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracing vs Scripting \n",
    "\n",
    "https://ppwwyyxx.com/blog/2022/TorchScript-Tracing-vs-Scripting/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 术语对齐\n",
    "\n",
    "* Export: 将pytorch eager模式的代码转换为计算图（TS-format）\n",
    "* Tracking: 使用`torch.jit.trace(model, input)`接口进行Export，机制是：给定一个输入后运行模型，计算所有执行的操作\n",
    "* Scripting: 使用`torch.jit.script(model)`接口进行Export，机制是：解析python源代码，把代码编译为计算图\n",
    "* TorchScript: 是一个有在上下文中被赋予多重含义的概念。大部分时候它是指被Export出来的计算图的表示；有时也表示Export方法。\n",
    "* Scriptable: 是指一个Module可以被`torch.jit.script`调用成功\n",
    "* Traceable: 是指一个Moduel可以被`jit.trace`导出成功。\n",
    "* Generalize: 是指一个traced model能够泛化到其他的input上去。Scripted models一般来说不会存在泛化问题。\n",
    "* Dynamic control flow：是依赖于输出的数据的控制操作，比如：\n",
    "    ```python\n",
    "    if x[0] == 4:\n",
    "        x += 1\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scripting存在问题\n",
    "\n",
    "Scripting编译器只能支持一个很小的python子集，对于大部分的basic syntax支持的挺好，但是对于classes, range, zip，动态类型, Union，**kwargs，继承等就基本不支持了。\n",
    "\n",
    "Scripting最大的问题是，它是一个黑盒，有时候即使导出成功了，也可能在一些边界的地方不work。没有一个清晰的list来说明哪些支持，哪些不支持。\n",
    "\n",
    "为了追求scriptable，会导致我们敬小慎微的在安全区域内写代码，整个代码会因为缺少高级抽象，而变得混乱，代码质量下降。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 让 traced model变得泛化\n",
    "\n",
    "Tracking机制相比于Scripting来说，它的约束边界非常清晰。\n",
    "\n",
    "1. Module要求是一个single-device的，不能是DataParallel的。\n",
    "2. Module中的计算只能是一个TS-format格式的计算图的组合，不能调用进行tensor或numpy array转换或者调用OpenCV的函数等。\n",
    "3. Module的输入只能是Tensor或者Tuple[Tensor]，或者Dict[str, Tensor]，或者是它们的nested组合。字典中的value必须是同一种类型。但module中的submodule没有输入类型的限制。\n",
    "4. 在Tracking过程中，tensor.size(),tensor.size()[0],tensor.shape[2]等操作的结果会被认为是一个Tensor，它们在eager模式下都是int，这样做是为了保持执行过程被跟踪。\n",
    "\n",
    "做到上面4点，一个Module往往是traceable的，但只是traecable还不够，我们需要generalization。下面的情况会破坏generatization\n",
    "\n",
    "1. 动态控制流\n",
    "2. 从Tensor中获取一个常量值：len(t)、t.item()、与numpy的一些转换等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    return torch.arange(x.shape[0])\n",
    "\n",
    "\n",
    "def f2(x):\n",
    "    return torch.arange(len(x))\n",
    "\n",
    "\n",
    "a = torch.rand(1)\n",
    "b = torch.rand(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.jit.trace(f1, a)(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_267643/1874855259.py:5: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  return torch.arange(len(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.jit.trace(f2, a)(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scripting支持除了forward外的其他接口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\n\npredict_keypoint(__torch__.___torch_mangle_80.Detector self, Tensor img, Tensor box) -> NoneType:\nExpected a value of type 'Tensor (inferred)' for argument 'box' but instead found type 'NoneType'.\nInferred 'box' to be of type 'Tensor' because it was not annotated with an explicit type.\n:\n  File \"/tmp/ipykernel_267643/1239083116.py\", line 7\n      box = self.predict_boxes(img)\n      if self.do_keypoint:\n          kpts = self.predict_keypoint(img, box)\n                 ~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m model \u001b[39m=\u001b[39m Detector()\n\u001b[1;32m     16\u001b[0m model\u001b[39m.\u001b[39mdo_keypoint \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m scripted_model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mscript(model)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.8/site-packages/torch/jit/_script.py:1284\u001b[0m, in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m   1283\u001b[0m     obj \u001b[39m=\u001b[39m call_prepare_scriptable_func(obj)\n\u001b[0;32m-> 1284\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49m_recursive\u001b[39m.\u001b[39;49mcreate_script_module(\n\u001b[1;32m   1285\u001b[0m         obj, torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49m_recursive\u001b[39m.\u001b[39;49minfer_methods_to_compile\n\u001b[1;32m   1286\u001b[0m     )\n\u001b[1;32m   1288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mdict\u001b[39m):\n\u001b[1;32m   1289\u001b[0m     \u001b[39mreturn\u001b[39;00m create_script_dict(obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.8/site-packages/torch/jit/_recursive.py:480\u001b[0m, in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tracing:\n\u001b[1;32m    479\u001b[0m     AttributeTypeIsSupportedChecker()\u001b[39m.\u001b[39mcheck(nn_module)\n\u001b[0;32m--> 480\u001b[0m \u001b[39mreturn\u001b[39;00m create_script_module_impl(nn_module, concrete_type, stubs_fn)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.8/site-packages/torch/jit/_recursive.py:546\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[39m# Compile methods if necessary\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[39mif\u001b[39;00m concrete_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m concrete_type_store\u001b[39m.\u001b[39mmethods_compiled:\n\u001b[0;32m--> 546\u001b[0m     create_methods_and_properties_from_stubs(concrete_type, method_stubs, property_stubs)\n\u001b[1;32m    547\u001b[0m     \u001b[39m# Create hooks after methods to ensure no name collisions between hooks and methods.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     \u001b[39m# If done before, hooks can overshadow methods that aren't exported.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m     create_hooks_from_stubs(concrete_type, hook_stubs, pre_hook_stubs)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.8/site-packages/torch/jit/_recursive.py:397\u001b[0m, in \u001b[0;36mcreate_methods_and_properties_from_stubs\u001b[0;34m(concrete_type, method_stubs, property_stubs)\u001b[0m\n\u001b[1;32m    394\u001b[0m property_defs \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mdef_ \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m property_stubs]\n\u001b[1;32m    395\u001b[0m property_rcbs \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mresolution_callback \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m property_stubs]\n\u001b[0;32m--> 397\u001b[0m concrete_type\u001b[39m.\u001b[39;49m_create_methods_and_properties(property_defs, property_rcbs, method_defs, method_rcbs, method_defaults)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \n\npredict_keypoint(__torch__.___torch_mangle_80.Detector self, Tensor img, Tensor box) -> NoneType:\nExpected a value of type 'Tensor (inferred)' for argument 'box' but instead found type 'NoneType'.\nInferred 'box' to be of type 'Tensor' because it was not annotated with an explicit type.\n:\n  File \"/tmp/ipykernel_267643/1239083116.py\", line 7\n      box = self.predict_boxes(img)\n      if self.do_keypoint:\n          kpts = self.predict_keypoint(img, box)\n                 ~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n"
     ]
    }
   ],
   "source": [
    "class Detector(torch.nn.Module):\n",
    "    do_keypoint: bool\n",
    "\n",
    "    def forward(self, img):\n",
    "        box = self.predict_boxes(img)\n",
    "        if self.do_keypoint:\n",
    "            kpts = self.predict_keypoint(img, box)\n",
    "\n",
    "    @torch.jit.export\n",
    "    def predict_boxes(self, img):\n",
    "        pass\n",
    "\n",
    "    @torch.jit.export\n",
    "    def predict_keypoint(self, img, box):\n",
    "        pass\n",
    "\n",
    "\n",
    "model = Detector()\n",
    "model.do_keypoint = True\n",
    "scripted_model = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `@script_if_tracking`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.6388, -0.2312,  0.8956, -0.9861],\n",
       "         [ 0.8869,  0.0744,  0.9764,  0.4940],\n",
       "         [ 0.9850,  0.5327,  0.8098, -0.1661]], grad_fn=<TanhBackward0>),\n",
       " tensor([[ 0.6388, -0.2312,  0.8956, -0.9861],\n",
       "         [ 0.8869,  0.0744,  0.9764,  0.4940],\n",
       "         [ 0.9850,  0.5327,  0.8098, -0.1661]], grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "@torch.jit.script_if_tracing\n",
    "def decision_gate(x):\n",
    "    if x.sum() > 0:\n",
    "        return x\n",
    "    else:\n",
    "        return -x\n",
    "\n",
    "\n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(decision_gate(self.linear(x)) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "\n",
    "x = torch.randn(3, 4)\n",
    "h = torch.randn(3, 4)\n",
    "model = MyCell()\n",
    "model(x, h)\n",
    "traced_model = torch.jit.trace(model, (x, h))\n",
    "traced_model(x, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Parallelism in Torchscript\n",
    "\n",
    "https://pytorch.org/tutorials/advanced/torch-script-parallelism.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
