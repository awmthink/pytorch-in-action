{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchScript\n",
    "\n",
    "TorchScript is an intermediate representation of a PyTorch model (subclass of nn.Module) that can then be run in a high-performance environment such as C++.\n",
    "\n",
    "TorchScript从Pytorch 1.0开始引入，它是一种新的progamming model，是Python语言的一个子集，能够被TorchScript的编译器进行解析、编译和优化。编译过后的torchscript可以被序列化成文件，随后被C++的pytorch backend加载执行。\n",
    "\n",
    "TorchSript能够支持torch包中的大量的operations，我们可以把torch理解为torchscript这个语言的标准库，使用这个标准库中的Tensor操作组成的一系列运算都能被TorchScript的编译器编译。同时，我们也会存在实现一些特殊算子的需求，我们可以使用C++/CUDA来扩展算子，这些算子基于ATen来实现，它们能够被TorchScript编译，进而其序列文件可以被Python或C++来加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Pytorch NN Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class MyDecisionGate(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x.sum() > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "\n",
    "\n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self, dg=None):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.dg = dg\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        if self.dg is None:\n",
    "            new_h = torch.tanh(self.linear(x) + h)\n",
    "        else:\n",
    "            new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell(\n",
      "  (linear): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n",
      "(tensor([[-0.7866, -0.7074, -0.6436,  0.9907],\n",
      "        [-0.8610,  0.9400, -0.0895, -0.3651],\n",
      "        [-0.8377,  0.2309,  0.6709, -0.5585]], grad_fn=<TanhBackward0>), tensor([[-0.7866, -0.7074, -0.6436,  0.9907],\n",
      "        [-0.8610,  0.9400, -0.0895, -0.3651],\n",
      "        [-0.8377,  0.2309,  0.6709, -0.5585]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "cell = MyCell()\n",
    "x = torch.randn(3, 4)\n",
    "h = torch.randn(3, 4)\n",
    "\n",
    "print(cell)\n",
    "print(cell(x, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracing Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell(\n",
      "  original_name=MyCell\n",
      "  (linear): Linear(original_name=Linear)\n",
      ")\n",
      "(tensor([[-0.7866, -0.7074, -0.6436,  0.9907],\n",
      "        [-0.8610,  0.9400, -0.0895, -0.3651],\n",
      "        [-0.8377,  0.2309,  0.6709, -0.5585]], grad_fn=<TanhBackward0>), tensor([[-0.7866, -0.7074, -0.6436,  0.9907],\n",
      "        [-0.8610,  0.9400, -0.0895, -0.3651],\n",
      "        [-0.8377,  0.2309,  0.6709, -0.5585]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "traced_cell = torch.jit.trace(cell, (x, h))\n",
    "print(traced_cell)\n",
    "print(traced_cell(x, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What exactly has this done? It has invoked the Module, recorded the operations that occurred when the Module was run, and created an instance of torch.jit.ScriptModule (of which TracedModule is an instance)\n",
    "\n",
    "TorchScript records its definitions in an Intermediate Representation (or IR), commonly referred to in Deep learning as a graph. We can examine the graph with the .graph property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self.1 : __torch__.___torch_mangle_30.MyCell,\n",
      "      %x : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu),\n",
      "      %h : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu)):\n",
      "  %linear : __torch__.torch.nn.modules.linear.___torch_mangle_29.Linear = prim::GetAttr[name=\"linear\"](%self.1)\n",
      "  %20 : Tensor = prim::CallMethod[name=\"forward\"](%linear, %x)\n",
      "  %11 : int = prim::Constant[value=1]() # /tmp/ipykernel_3199122/808754513.py:20:0\n",
      "  %12 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::add(%20, %h, %11) # /tmp/ipykernel_3199122/808754513.py:20:0\n",
      "  %13 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::tanh(%12) # /tmp/ipykernel_3199122/808754513.py:20:0\n",
      "  %14 : (Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu), Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu)) = prim::TupleConstruct(%13, %13)\n",
      "  return (%14)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traced_cell.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is a very low-level representation and most of the information contained in the graph is not useful for end users. Instead, we can use the .code property to give a Python-syntax interpretation of the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  linear = self.linear\n",
      "  _0 = torch.tanh(torch.add((linear).forward(x, ), h))\n",
      "  return (_0, _0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why use trace module\n",
    "\n",
    "* TorchScript code can be invoked in its own interpreter, which is basically a restricted Python interpreter. This interpreter does not acquire the Global Interpreter Lock, and so many requests can be processed on the same instance simultaneously.\n",
    "* This format allows us to save the whole model to disk and load it into another environment, such as in a server written in a language other than Python\n",
    "* TorchScript gives us a representation in which we can do compiler optimizations on the code to provide more efficient execution\n",
    "* TorchScript allows us to interface with many backend/device runtimes that require a broader view of the program than individual operators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uing Scripting to Convert Modules\n",
    "\n",
    "## Tracing Module存在的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = (linear).forward(x, )\n",
      "  _1 = (dg).forward(_0, )\n",
      "  _2 = torch.tanh(torch.add(_0, h))\n",
      "  return (_2, _2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3199122/808754513.py:6: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if x.sum() > 0:\n"
     ]
    }
   ],
   "source": [
    "cell = MyCell(MyDecisionGate())\n",
    "traced_cell = torch.jit.trace(cell, (x, h))\n",
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the .code output, we can see that the if-else branch is nowhere to be found! Why? Tracing does exactly what we said it would: run the code, record the operations that happen and construct a ScriptModule that does exactly that. Unfortunately, things like control flow are erased.\n",
    "\n",
    "How can we faithfully represent this module in TorchScript? We provide a script compiler, which does direct analysis of your Python source code to transform it into TorchScript. Let’s convert MyDecisionGate using the script compiler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  if bool(torch.gt(torch.sum(x), 0)):\n",
      "    _0 = x\n",
      "  else:\n",
      "    _0 = torch.neg(x)\n",
      "  return _0\n",
      "\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n",
      "  new_h = torch.tanh(_0)\n",
      "  return (new_h, new_h)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scripted_cell = torch.jit.script(cell)\n",
    "print(scripted_cell.dg.code)\n",
    "print(scripted_cell.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixing Scripting and Tracking\n",
    "\n",
    "Some situations call for using tracing rather than scripting (e.g. a module has many architectural decisions that are made based on constant Python values that we would like to not appear in TorchScript). In this case, scripting can be composed with tracing: `torch.jit.script` will inline the code for a traced module, and tracing will inline the code for a scripted module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    xs: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  h = torch.zeros([3, 4])\n",
      "  y = torch.zeros([3, 4])\n",
      "  y0 = y\n",
      "  h0 = h\n",
      "  for i in range(torch.size(xs, 0)):\n",
      "    cell = self.cell\n",
      "    _0 = (cell).forward(torch.select(xs, 0, i), h0, )\n",
      "    y1, h1, = _0\n",
      "    y0, h0 = y1, h1\n",
      "  return (y0, h0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class MyRNNLoop(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyRNNLoop, self).__init__()\n",
    "        self.cell = torch.jit.trace(MyCell(scripted_cell.dg), (x, h))\n",
    "\n",
    "    def forward(self, xs):\n",
    "        h, y = torch.zeros(3, 4), torch.zeros(3, 4)\n",
    "        for i in range(xs.size(0)):\n",
    "            y, h = self.cell(xs[i], h)\n",
    "        return y, h\n",
    "\n",
    "\n",
    "rnn_loop = torch.jit.script(MyRNNLoop())\n",
    "print(rnn_loop.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And an example of the second case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    xs: Tensor) -> Tensor:\n",
      "  loop = self.loop\n",
      "  _0, y, = (loop).forward(xs, )\n",
      "  return torch.relu(y)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class WrapRNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WrapRNN, self).__init__()\n",
    "        self.loop = torch.jit.script(MyRNNLoop())\n",
    "\n",
    "    def forward(self, xs):\n",
    "        y, h = self.loop(xs)\n",
    "        return torch.relu(y)\n",
    "\n",
    "\n",
    "traced = torch.jit.trace(WrapRNN(), (torch.rand(10, 3, 4)))\n",
    "print(traced.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(\n",
      "  original_name=WrapRNN\n",
      "  (loop): RecursiveScriptModule(\n",
      "    original_name=MyRNNLoop\n",
      "    (cell): RecursiveScriptModule(\n",
      "      original_name=MyCell\n",
      "      (dg): RecursiveScriptModule(original_name=MyDecisionGate)\n",
      "      (linear): RecursiveScriptModule(original_name=Linear)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "def forward(self,\n",
      "    xs: Tensor) -> Tensor:\n",
      "  loop = self.loop\n",
      "  _0, y, = (loop).forward(xs, )\n",
      "  return torch.relu(y)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "traced.save(\"/tmp/wrapped_rnn.pt\")\n",
    "loaded = torch.jit.load(\"/tmp/wrapped_rnn.pt\")\n",
    "print(loaded)\n",
    "print(loaded.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracing vs Scripting \n",
    "\n",
    "https://ppwwyyxx.com/blog/2022/TorchScript-Tracing-vs-Scripting/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
