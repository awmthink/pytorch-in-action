{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shifted Windows Transformer\n",
    "\n",
    "* https://amaarora.github.io/posts/2022-07-04-swintransformerv1.html\n",
    "* https://www.zhihu.com/question/521494294/answer/3178312617"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, SwinForImageClassification\n",
    "import torch\n",
    "from torch import nn\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/yangyansheng/.cache/huggingface/modules/datasets_modules/datasets/huggingface--cats-image/68fbc793fb10cd165e490867f5d61fa366086ea40c73e549a020103dcb4f597e (last modified on Mon Oct 14 11:03:54 2024) since it couldn't be found locally at huggingface/cats-image, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabby, tabby cat\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"huggingface/cats-image\", trust_remote_code=True)\n",
    "image = dataset[\"test\"][\"image\"][0]\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\n",
    "    \"microsoft/swin-tiny-patch4-window7-224\"\n",
    ")\n",
    "model = SwinForImageClassification.from_pretrained(\n",
    "    \"microsoft/swin-tiny-patch4-window7-224\"\n",
    ")\n",
    "\n",
    "inputs = image_processor(image, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "predicted_label = logits.argmax(-1).item()\n",
    "print(model.config.id2label[predicted_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pair-wise relative position index for each token inside the window\n",
    "win_w = 5\n",
    "win_h = 5\n",
    "coords = torch.stack(\n",
    "    torch.meshgrid((torch.arange(win_h), torch.arange(win_w)), indexing=\"ij\")\n",
    ")  # 2, Wh, Ww\n",
    "coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [2, 2, 2, 2, 2],\n",
       "        [3, 3, 3, 3, 3],\n",
       "        [4, 4, 4, 4, 4]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 代表了所有 patches 在 grid 中的垂直方向的坐标\n",
    "coords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 代表了所有 patches 在 grid 中的水平方向的坐标\n",
    "coords[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0, -1, -1, -1, -1, -1, -2, -2, -2, -2, -2, -3, -3, -3,\n",
       "        -3, -3, -4, -4, -4, -4, -4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_coords = (\n",
    "    coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    ")  # 2, Wh*Ww, Wh*Ww\n",
    "\n",
    "# relative_coords[0][i][j] 代表的是被 flatten 成一维后，第 i 个 Patch 和第 j 个 Patch 之间的 y 坐标的距离\n",
    "# relative_coords[0][i][j] 代表的是被 flatten 成一维后，第 i 个 Patch 和第 j 个 Patch 之间的 x 坐标的距离\n",
    "relative_coords[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative_coords[i][j] 代表的第 i 个 patch 和第 j 个 patch 之间的 x 和 y 坐标的距离\n",
    "relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n",
    "relative_coords[:, :, 0] += win_h - 1  # shift to start from 0\n",
    "relative_coords[:, :, 1] += win_w - 1\n",
    "relative_coords[:, :, 0] *= (\n",
    "    2 * win_w - 1\n",
    ")  # 2 * win_w - 1 是 x 方向上两个 Patch之间距离的最大值\n",
    "\n",
    "# dist = y * (2 * win_w - 1) + x\n",
    "# relative_coords[i][j] 就代表第 i 个 patch 和第 j 个 path之间的相对距离\n",
    "relative_coords = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[40, 39, 38, 37, 36, 31, 30, 29, 28, 27, 22, 21, 20, 19, 18, 13, 12, 11,\n",
       "         10,  9,  4,  3,  2,  1,  0],\n",
       "        [41, 40, 39, 38, 37, 32, 31, 30, 29, 28, 23, 22, 21, 20, 19, 14, 13, 12,\n",
       "         11, 10,  5,  4,  3,  2,  1],\n",
       "        [42, 41, 40, 39, 38, 33, 32, 31, 30, 29, 24, 23, 22, 21, 20, 15, 14, 13,\n",
       "         12, 11,  6,  5,  4,  3,  2],\n",
       "        [43, 42, 41, 40, 39, 34, 33, 32, 31, 30, 25, 24, 23, 22, 21, 16, 15, 14,\n",
       "         13, 12,  7,  6,  5,  4,  3],\n",
       "        [44, 43, 42, 41, 40, 35, 34, 33, 32, 31, 26, 25, 24, 23, 22, 17, 16, 15,\n",
       "         14, 13,  8,  7,  6,  5,  4],\n",
       "        [49, 48, 47, 46, 45, 40, 39, 38, 37, 36, 31, 30, 29, 28, 27, 22, 21, 20,\n",
       "         19, 18, 13, 12, 11, 10,  9],\n",
       "        [50, 49, 48, 47, 46, 41, 40, 39, 38, 37, 32, 31, 30, 29, 28, 23, 22, 21,\n",
       "         20, 19, 14, 13, 12, 11, 10],\n",
       "        [51, 50, 49, 48, 47, 42, 41, 40, 39, 38, 33, 32, 31, 30, 29, 24, 23, 22,\n",
       "         21, 20, 15, 14, 13, 12, 11],\n",
       "        [52, 51, 50, 49, 48, 43, 42, 41, 40, 39, 34, 33, 32, 31, 30, 25, 24, 23,\n",
       "         22, 21, 16, 15, 14, 13, 12],\n",
       "        [53, 52, 51, 50, 49, 44, 43, 42, 41, 40, 35, 34, 33, 32, 31, 26, 25, 24,\n",
       "         23, 22, 17, 16, 15, 14, 13],\n",
       "        [58, 57, 56, 55, 54, 49, 48, 47, 46, 45, 40, 39, 38, 37, 36, 31, 30, 29,\n",
       "         28, 27, 22, 21, 20, 19, 18],\n",
       "        [59, 58, 57, 56, 55, 50, 49, 48, 47, 46, 41, 40, 39, 38, 37, 32, 31, 30,\n",
       "         29, 28, 23, 22, 21, 20, 19],\n",
       "        [60, 59, 58, 57, 56, 51, 50, 49, 48, 47, 42, 41, 40, 39, 38, 33, 32, 31,\n",
       "         30, 29, 24, 23, 22, 21, 20],\n",
       "        [61, 60, 59, 58, 57, 52, 51, 50, 49, 48, 43, 42, 41, 40, 39, 34, 33, 32,\n",
       "         31, 30, 25, 24, 23, 22, 21],\n",
       "        [62, 61, 60, 59, 58, 53, 52, 51, 50, 49, 44, 43, 42, 41, 40, 35, 34, 33,\n",
       "         32, 31, 26, 25, 24, 23, 22],\n",
       "        [67, 66, 65, 64, 63, 58, 57, 56, 55, 54, 49, 48, 47, 46, 45, 40, 39, 38,\n",
       "         37, 36, 31, 30, 29, 28, 27],\n",
       "        [68, 67, 66, 65, 64, 59, 58, 57, 56, 55, 50, 49, 48, 47, 46, 41, 40, 39,\n",
       "         38, 37, 32, 31, 30, 29, 28],\n",
       "        [69, 68, 67, 66, 65, 60, 59, 58, 57, 56, 51, 50, 49, 48, 47, 42, 41, 40,\n",
       "         39, 38, 33, 32, 31, 30, 29],\n",
       "        [70, 69, 68, 67, 66, 61, 60, 59, 58, 57, 52, 51, 50, 49, 48, 43, 42, 41,\n",
       "         40, 39, 34, 33, 32, 31, 30],\n",
       "        [71, 70, 69, 68, 67, 62, 61, 60, 59, 58, 53, 52, 51, 50, 49, 44, 43, 42,\n",
       "         41, 40, 35, 34, 33, 32, 31],\n",
       "        [76, 75, 74, 73, 72, 67, 66, 65, 64, 63, 58, 57, 56, 55, 54, 49, 48, 47,\n",
       "         46, 45, 40, 39, 38, 37, 36],\n",
       "        [77, 76, 75, 74, 73, 68, 67, 66, 65, 64, 59, 58, 57, 56, 55, 50, 49, 48,\n",
       "         47, 46, 41, 40, 39, 38, 37],\n",
       "        [78, 77, 76, 75, 74, 69, 68, 67, 66, 65, 60, 59, 58, 57, 56, 51, 50, 49,\n",
       "         48, 47, 42, 41, 40, 39, 38],\n",
       "        [79, 78, 77, 76, 75, 70, 69, 68, 67, 66, 61, 60, 59, 58, 57, 52, 51, 50,\n",
       "         49, 48, 43, 42, 41, 40, 39],\n",
       "        [80, 79, 78, 77, 76, 71, 70, 69, 68, 67, 62, 61, 60, 59, 58, 53, 52, 51,\n",
       "         50, 49, 44, 43, 42, 41, 40]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10,  9,  8,  7,\n",
       "          6,  5,  4,  3,  2,  1,  0],\n",
       "        [25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10,  9,  8,\n",
       "          7,  6,  5,  4,  3,  2,  1],\n",
       "        [26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10,  9,\n",
       "          8,  7,  6,  5,  4,  3,  2],\n",
       "        [27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10,\n",
       "          9,  8,  7,  6,  5,  4,  3],\n",
       "        [28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11,\n",
       "         10,  9,  8,  7,  6,  5,  4],\n",
       "        [29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12,\n",
       "         11, 10,  9,  8,  7,  6,  5],\n",
       "        [30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13,\n",
       "         12, 11, 10,  9,  8,  7,  6],\n",
       "        [31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14,\n",
       "         13, 12, 11, 10,  9,  8,  7],\n",
       "        [32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15,\n",
       "         14, 13, 12, 11, 10,  9,  8],\n",
       "        [33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16,\n",
       "         15, 14, 13, 12, 11, 10,  9],\n",
       "        [34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17,\n",
       "         16, 15, 14, 13, 12, 11, 10],\n",
       "        [35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18,\n",
       "         17, 16, 15, 14, 13, 12, 11],\n",
       "        [36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19,\n",
       "         18, 17, 16, 15, 14, 13, 12],\n",
       "        [37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20,\n",
       "         19, 18, 17, 16, 15, 14, 13],\n",
       "        [38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21,\n",
       "         20, 19, 18, 17, 16, 15, 14],\n",
       "        [39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22,\n",
       "         21, 20, 19, 18, 17, 16, 15],\n",
       "        [40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23,\n",
       "         22, 21, 20, 19, 18, 17, 16],\n",
       "        [41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24,\n",
       "         23, 22, 21, 20, 19, 18, 17],\n",
       "        [42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25,\n",
       "         24, 23, 22, 21, 20, 19, 18],\n",
       "        [43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26,\n",
       "         25, 24, 23, 22, 21, 20, 19],\n",
       "        [44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27,\n",
       "         26, 25, 24, 23, 22, 21, 20],\n",
       "        [45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28,\n",
       "         27, 26, 25, 24, 23, 22, 21],\n",
       "        [46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29,\n",
       "         28, 27, 26, 25, 24, 23, 22],\n",
       "        [47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30,\n",
       "         29, 28, 27, 26, 25, 24, 23],\n",
       "        [48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31,\n",
       "         30, 29, 28, 27, 26, 25, 24]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0, win_h * win_w)\n",
    "\n",
    "real_coor = x[:, None] - x[None, :]\n",
    "real_coor += win_h * win_w - 1\n",
    "real_coor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.pixel_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 4\n",
    "window_size = 7\n",
    "embed_dim = 96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SwinPatchEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "_, num_channels, height, weight = inputs.pixel_values.shape\n",
    "patch_projection = nn.Conv2d(num_channels, embed_dim, patch_size, patch_size)\n",
    "\n",
    "# [1, 3, 224, 224] -> [1, 96, 56, 56]\n",
    "embeddings = patch_projection(inputs.pixel_values)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, height, width = embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 3136])\n",
      "torch.Size([1, 3136, 96])\n"
     ]
    }
   ],
   "source": [
    "embeddings = embeddings.flatten(2)\n",
    "print(embeddings.shape)\n",
    "embeddings = embeddings.transpose(1, 2)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window SelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 56, 56, 96])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states = embeddings.view(-1, height, width, embed_dim)\n",
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 7, 8, 7, 96])\n",
      "torch.Size([1, 8, 8, 7, 7, 96])\n",
      "torch.Size([64, 49, 96])\n"
     ]
    }
   ],
   "source": [
    "hidden_states_windows = hidden_states.view(\n",
    "    -1, height // window_size, window_size, width // window_size, window_size, embed_dim\n",
    ")\n",
    "print(hidden_states_windows.shape)\n",
    "hidden_states_windows = hidden_states_windows.permute(0, 1, 3, 2, 4, 5)\n",
    "print(hidden_states_windows.shape)\n",
    "\n",
    "# 将窗口个数的维度合并到 batchsize 中，将每个7x7 的窗口合成一个 序列长度维度\n",
    "hidden_states_windows = hidden_states_windows.contiguous().view(\n",
    "    -1, window_size * window_size, embed_dim\n",
    ")\n",
    "print(hidden_states_windows.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift Windows SelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 56, 56, 96])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states = embeddings.view(-1, height, width, embed_dim)\n",
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14],\n",
       "        [15, 16, 17, 18, 19],\n",
       "        [20, 21, 22, 23, 24]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(25).view((5, 5))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18, 19, 15, 16, 17],\n",
       "        [23, 24, 20, 21, 22],\n",
       "        [ 3,  4,  0,  1,  2],\n",
       "        [ 8,  9,  5,  6,  7],\n",
       "        [13, 14, 10, 11, 12]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.roll(t, shifts=(2, 2), dims=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch Mergeings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
