{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch import Tensor\n",
                "import math\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from typing import Tuple, Optional"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 一些辅助函数"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# compare_output 用于计算 手工实现的结果与 pytorch 实现的结果是否一致\n",
                "def compare_output(output_tag, output_ref, output, rtol=1e-5, atol=1e-8):\n",
                "    flag = torch.allclose(output_ref, output, rtol=rtol, atol=atol)\n",
                "    flag_emoj = \"✅\" if flag else \"❌\"\n",
                "    print(f\"{output_tag}: {flag_emoj}\")\n",
                "\n",
                "\n",
                "# show heatmaps 用于对多头注意力机制中输出的注意力权重矩阵进行可视化\n",
                "def show_heatmaps(\n",
                "    matrics, xlabel, ylabel, titles=None, figsize=(2.5, 2.5), cmap=\"Reds\"\n",
                "):\n",
                "    \"\"\"\n",
                "    matrics: [batch_size, nheads, L, L]\n",
                "    \"\"\"\n",
                "    # d2l.use_svg_display()\n",
                "    # 每行显示一个batch 中的一个句子，每列显示一个 head\n",
                "    num_rows, num_cols = matrics.shape[0], matrics.shape[1]\n",
                "    fig, axes = plt.subplots(\n",
                "        num_rows, num_cols, figsize=figsize, sharex=True, sharey=True, squeeze=False\n",
                "    )\n",
                "    for i, (row_axes, row_matrics) in enumerate(zip(axes, matrics)):\n",
                "        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrics)):\n",
                "            # 绘制子窗口中的图像\n",
                "            pcm = ax.imshow(matrix.detach().numpy(), cmap=cmap)\n",
                "            # 在整个画布的最后一行显示xlabel\n",
                "            if i == num_rows - 1:\n",
                "                ax.set_xlabel(xlabel)\n",
                "            # 在整个画布的第一列显示ylabel\n",
                "            if j == 0:\n",
                "                ax.set_ylabel(ylabel)\n",
                "            if titles:\n",
                "                ax.set_title(titles[j])\n",
                "    # 显示colorbar\n",
                "    fig.colorbar(pcm, ax=axes, shrink=0.6)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Transformer 相关的参数定义"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "d_model = 512  # 输入特征的维度\n",
                "nhead = 8  # AttentionHead 的数量\n",
                "num_encoder_layers = 6\n",
                "num_decoder_layers = 6\n",
                "dim_feedforward = 2048\n",
                "dropout = 0\n",
                "batch_first = True\n",
                "norm_first = True\n",
                "bias = True"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Token Embedding\n",
                "\n",
                "我们可以把 Token Embedding 看成一个 `[vocab_size, embed_size]`的查找表矩阵，每行对应了一个 token_id 的 embedding vector。\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Pytorch 中的 `nn.Embedding`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "vocab_size = 32000\n",
                "token_embedding_layer = nn.Embedding(vocab_size, d_model)\n",
                "\n",
                "batch_size = 2\n",
                "seqlen = 5\n",
                "\n",
                "input_token_ids = torch.randint(0, vocab_size, (batch_size, seqlen), dtype=torch.long)\n",
                "token_embeddings_torch = token_embedding_layer(input_token_ids)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 手动查找"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "token_embeddings: ✅\n"
                    ]
                }
            ],
            "source": [
                "# Pytorch 支持使用一个 2d Tensor 作为 Indices 来进行 Tensor 来索引\n",
                "token_embeddings = token_embedding_layer.weight[input_token_ids]\n",
                "compare_output(\"token_embeddings\", token_embeddings_torch, token_embeddings)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 位置编码\n",
                "\n",
                "$PE_{(pos,2i)} = \\sin\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right)$\n",
                "\n",
                "$PE_{(pos,2i + 1)} = \\cos\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right)$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([1.0000, 0.9734, 0.9475, 0.9222, 0.8977])"
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import torch\n",
                "\n",
                "embedding_mat = torch.pow(1000, -torch.arange(0, 512, 2) / 512)\n",
                "embedding_mat[:5]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([1.0000, 0.9647, 0.9306, 0.8977, 0.8660])"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import torch\n",
                "\n",
                "embedding_mat = torch.pow(10000, -torch.arange(0, 512, 2) / 512)\n",
                "embedding_mat[:5]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "max_seqlen = 512\n",
                "embed_size = 2048\n",
                "\n",
                "position_mat = torch.arange(0, max_seqlen)[:, None]  # [512, 1]\n",
                "embedding_mat = torch.pow(10000, torch.arange(0, embed_size, 2) / embed_size)[\n",
                "    None, :\n",
                "]  # [1, 1024]\n",
                "position_embedding_matrix = position_mat / embedding_mat  # [512, 1024]\n",
                "position_embed = torch.zeros(max_seqlen, embed_size)\n",
                "position_embed[:, 0::2] = torch.sin(position_embedding_matrix)\n",
                "position_embed[:, 1::2] = torch.cos(position_embedding_matrix)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "torch.Size([2, 10, 2048])\n"
                    ]
                }
            ],
            "source": [
                "position_embedding_layer = nn.Embedding(max_seqlen, embed_size)\n",
                "position_embedding_layer.weight = nn.Parameter(\n",
                "    position_embed, requires_grad=False\n",
                ")\n",
                "\n",
                "seq_len = 10\n",
                "batch_size = 2\n",
                "# input_positions 为输入的句子序列对应的位置 id\n",
                "input_positions = torch.arange(0, seq_len)[None, :].repeat((batch_size, 1))\n",
                "# 也可以直接对 position_embedding_matrix 进行 2 维索引\n",
                "position_embedding = position_embedding_layer(input_positions)\n",
                "print(position_embedding.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# MultiHeadAttention"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 生成 Padding Mask 和 Attention Mask"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_padding_mask(key_seq_lengths, max_seq_len):\n",
                "    batch_size = len(key_seq_lengths)\n",
                "    key_padding_mask = torch.arange(1, max_seq_len + 1)\n",
                "    key_padding_mask = key_padding_mask[None, :].repeat(batch_size, 1)\n",
                "    key_padding_mask = key_padding_mask > torch.tensor(key_seq_lengths)[:, None]\n",
                "    return key_padding_mask\n",
                "\n",
                "\n",
                "def get_causal_attn_mask(max_seq_len):\n",
                "    attn_mask = torch.ones(max_seq_len, max_seq_len).tril() == 0\n",
                "    return attn_mask"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Pytorch API 的使用"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "torch_attn = nn.MultiheadAttention(\n",
                "    d_model,\n",
                "    nhead,\n",
                "    dropout=dropout,\n",
                "    bias=bias,\n",
                "    batch_first=batch_first,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "batch_size = 4\n",
                "seqlen = 10\n",
                "\n",
                "q_tensor = torch.randn(batch_size, seqlen, d_model)\n",
                "k_tensor = torch.randn(batch_size, seqlen, d_model)\n",
                "v_tensor = torch.randn(batch_size, seqlen, d_model)\n",
                "\n",
                "batch_seq_len = [4, 9, 6, 10]\n",
                "padding_mask = get_padding_mask(batch_seq_len, seqlen)\n",
                "attn_mask = get_causal_attn_mask(seqlen)\n",
                "\n",
                "need_weights = True\n",
                "# [batch_size, seqlen, d_model], [batch_size, nheads, seqlen, seqlen]\n",
                "attn_output_torch, attn_output_weights_torch = torch_attn(\n",
                "    q_tensor,\n",
                "    k_tensor,\n",
                "    v_tensor,\n",
                "    key_padding_mask=padding_mask,\n",
                "    attn_mask=attn_mask,\n",
                "    need_weights=need_weights,\n",
                "    average_attn_weights=False,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "in_proj_weight = torch_attn.in_proj_weight  # [3 * d_model, d_model]\n",
                "in_proj_bias = torch_attn.in_proj_bias  # [3 * d_model]\n",
                "out_proj_weight = torch_attn.out_proj.weight  # [d_model, d_model]\n",
                "out_proj_bias = torch_attn.out_proj.bias  # [d_model]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 手动实现 MHA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "def multihead_attn(\n",
                "    query: Tensor,  # [N,L,Eq]\n",
                "    key: Tensor,\n",
                "    value: Tensor,\n",
                "    nheads,\n",
                "    in_proj_weight: Tensor,\n",
                "    in_proj_bias: Tensor,\n",
                "    out_proj_weight: Tensor,\n",
                "    out_proj_bias: Tensor,\n",
                "    dropout_p: float = 0,\n",
                "    key_padding_mask: Tensor = None,\n",
                "    attn_mask: Tensor = None,\n",
                "    need_weights=True,\n",
                "):\n",
                "    q_proj_weight, k_proj_weight, v_proj_weight = in_proj_weight.chunk(3)\n",
                "    q_proj_bias, k_proj_bias, v_proj_bias = in_proj_bias.chunk(3)\n",
                "\n",
                "    q_proj = query @ q_proj_weight.t() + q_proj_bias  # N,L,E\n",
                "    k_proj = key @ k_proj_weight.t() + k_proj_bias\n",
                "    v_proj = value @ v_proj_weight.t() + v_proj_bias\n",
                "\n",
                "    batch_size, qlen, embed_size = q_proj.shape\n",
                "    klen = k_proj.size(1)\n",
                "    head_embed_size = embed_size // nheads\n",
                "    q_proj = q_proj.reshape(batch_size, qlen, nhead, head_embed_size).permute(\n",
                "        0, 2, 1, 3\n",
                "    )\n",
                "    k_proj = k_proj.reshape(batch_size, klen, nhead, head_embed_size).permute(\n",
                "        0, 2, 1, 3\n",
                "    )\n",
                "    v_proj = v_proj.reshape(batch_size, klen, nhead, head_embed_size).permute(\n",
                "        0, 2, 1, 3\n",
                "    )\n",
                "    # [batch_size, nhead, qlen, ken]\n",
                "    atten_weights = q_proj @ k_proj.transpose(2, 3) / math.sqrt(head_embed_size)\n",
                "\n",
                "    if key_padding_mask is not None:\n",
                "        key_padding_mask = torch.where(key_padding_mask, float(\"-inf\"), 0)\n",
                "        atten_weights += key_padding_mask.view(batch_size, 1, 1, klen)\n",
                "\n",
                "    if attn_mask is not None:\n",
                "        attn_mask = torch.where(attn_mask, float(\"-inf\"), 0)\n",
                "        atten_weights += attn_mask\n",
                "\n",
                "    atten_weights = F.softmax(atten_weights, dim=-1)\n",
                "\n",
                "    if dropout_p > 0:\n",
                "        atten_weights = F.dropout(atten_weights, p=dropout_p)\n",
                "\n",
                "    attn_output = atten_weights @ v_proj  # [batch_size, nhead, qlen, head_embed_size]\n",
                "    # [batch_size, qlen, embed_size]\n",
                "    attn_output = attn_output.permute(0, 2, 1, 3).reshape(batch_size, qlen, embed_size)\n",
                "    attn_output = attn_output @ out_proj_weight.t() + out_proj_bias\n",
                "\n",
                "    if need_weights:\n",
                "        return attn_output, atten_weights\n",
                "\n",
                "    return attn_output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "attn_output, attn_output_weights = multihead_attn(\n",
                "    q_tensor,\n",
                "    k_tensor,\n",
                "    v_tensor,\n",
                "    nhead,\n",
                "    in_proj_weight,\n",
                "    in_proj_bias,\n",
                "    out_proj_weight,\n",
                "    out_proj_bias,\n",
                "    key_padding_mask=padding_mask,\n",
                "    attn_mask=attn_mask,\n",
                "    need_weights=need_weights,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "attn_output: ✅\n",
                        "attn_output_weights: ✅\n"
                    ]
                }
            ],
            "source": [
                "compare_output(\"attn_output\", attn_output, attn_output_torch)\n",
                "compare_output(\"attn_output_weights\", attn_output_weights_torch, attn_output_weights)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Position-wise Feedforward"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "def feedforward_block(\n",
                "    x,\n",
                "    linear1_weight,\n",
                "    linear1_bias,\n",
                "    linear2_weight,\n",
                "    linear2_bias,\n",
                "    dropout_p=0,\n",
                "):\n",
                "    x = x @ linear1_weight.t() + linear1_bias\n",
                "    x = F.relu(x)\n",
                "    x = F.dropout(x, dropout_p)\n",
                "    x = x @ linear2_weight.t() + linear2_bias\n",
                "    return x"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# TransformerEncoderLayer"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Pytorch API 的使用"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "torch_encoder_layer = nn.TransformerEncoderLayer(\n",
                "    d_model,\n",
                "    nhead,\n",
                "    dim_feedforward,\n",
                "    dropout=dropout,\n",
                "    batch_first=batch_first,\n",
                "    norm_first=norm_first,\n",
                "    bias=bias,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "batch_size = 4\n",
                "seqlen = 10\n",
                "\n",
                "input_tensor = torch.randn(batch_size, seqlen, d_model)\n",
                "encoder_layer_output_torch = torch_encoder_layer(input_tensor)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##  手动实现"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "def transformer_encoder_layer_fwd(\n",
                "    src,\n",
                "    nhead,\n",
                "    in_proj_weight,\n",
                "    in_proj_bias,\n",
                "    out_proj_weight,\n",
                "    out_proj_bias,\n",
                "    linear1_weight,\n",
                "    linear1_bias,\n",
                "    linear2_weight,\n",
                "    linear2_bias,\n",
                "    norm1_weight,\n",
                "    norm1_bias,\n",
                "    norm2_weight,\n",
                "    norm2_bias,\n",
                "    dropout_p=0,\n",
                "    layer_norm_eps=1e-5,\n",
                "    attn_mask=None,\n",
                "    padding_mask=None,\n",
                "):\n",
                "    norm = F.layer_norm(\n",
                "        src, (src.size(-1),), norm1_weight, norm1_bias, eps=layer_norm_eps\n",
                "    )\n",
                "    out = multihead_attn(\n",
                "        norm,\n",
                "        norm,\n",
                "        norm,\n",
                "        nhead,\n",
                "        in_proj_weight,\n",
                "        in_proj_bias,\n",
                "        out_proj_weight,\n",
                "        out_proj_bias,\n",
                "        dropout_p,\n",
                "        padding_mask,\n",
                "        attn_mask,\n",
                "        need_weights=False,\n",
                "    )\n",
                "    out += src\n",
                "    norm = F.layer_norm(\n",
                "        out, (out.size(-1),), norm2_weight, norm2_bias, eps=layer_norm_eps\n",
                "    )\n",
                "    out = (\n",
                "        feedforward_block(\n",
                "            norm, linear1_weight, linear1_bias, linear2_weight, linear2_bias, dropout_p\n",
                "        )\n",
                "        + out\n",
                "    )\n",
                "    return out"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "in_proj_weight = torch_encoder_layer.self_attn.in_proj_weight\n",
                "in_proj_bias = torch_encoder_layer.self_attn.in_proj_bias\n",
                "out_proj_weight = torch_encoder_layer.self_attn.out_proj.weight\n",
                "out_proj_bias = torch_encoder_layer.self_attn.out_proj.bias\n",
                "linear1_weight = torch_encoder_layer.linear1.weight\n",
                "linear1_bias = torch_encoder_layer.linear1.bias\n",
                "linear2_weight = torch_encoder_layer.linear2.weight\n",
                "linear2_bias = torch_encoder_layer.linear2.bias\n",
                "norm1_weight = torch_encoder_layer.norm1.weight\n",
                "norm1_bias = torch_encoder_layer.norm1.bias\n",
                "norm2_weight = torch_encoder_layer.norm2.weight\n",
                "norm2_bias = torch_encoder_layer.norm2.bias\n",
                "\n",
                "\n",
                "encoder_layer_output = transformer_encoder_layer_fwd(\n",
                "    input_tensor,\n",
                "    nhead,\n",
                "    in_proj_weight,\n",
                "    in_proj_bias,\n",
                "    out_proj_weight,\n",
                "    out_proj_bias,\n",
                "    linear1_weight,\n",
                "    linear1_bias,\n",
                "    linear2_weight,\n",
                "    linear2_bias,\n",
                "    norm1_weight,\n",
                "    norm1_bias,\n",
                "    norm2_weight,\n",
                "    norm2_bias,\n",
                "    dropout_p=dropout,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "encoder_layer_output: ✅\n"
                    ]
                }
            ],
            "source": [
                "compare_output(\n",
                "    \"encoder_layer_output\", encoder_layer_output_torch, encoder_layer_output, atol=1e-6\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# TransformerDecoderLayer"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Pytorch 实现"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "decoder_layer_torch = nn.TransformerDecoderLayer(\n",
                "    d_model,\n",
                "    nhead,\n",
                "    dim_feedforward=dim_feedforward,\n",
                "    dropout=dropout,\n",
                "    batch_first=batch_first,\n",
                "    norm_first=norm_first,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": [
                "batch_size = 2\n",
                "src_seq_len = [8, 10]\n",
                "tgt_seq_len = [6, 4]\n",
                "\n",
                "encoder_memory = torch.randn(batch_size, max(src_seq_len), d_model)\n",
                "tgt_input_tensor = torch.randn(batch_size, max(tgt_seq_len), d_model)\n",
                "\n",
                "src_padding_mask = get_padding_mask(src_seq_len, max(src_seq_len))\n",
                "tgt_padding_mask = get_padding_mask(tgt_seq_len, max(tgt_seq_len))\n",
                "tgt_mask = get_causal_attn_mask(max(tgt_seq_len))\n",
                "\n",
                "decoder_output_torch = decoder_layer_torch(\n",
                "    tgt_input_tensor,\n",
                "    encoder_memory,\n",
                "    tgt_mask=tgt_mask,\n",
                "    tgt_key_padding_mask=tgt_padding_mask,\n",
                "    memory_key_padding_mask=src_padding_mask,\n",
                "    tgt_is_causal=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 从 Pytorch Module 中获取每一层的参数"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "self_attn_in_proj_weight = decoder_layer_torch.self_attn.in_proj_weight\n",
                "self_attn_in_proj_bias = decoder_layer_torch.self_attn.in_proj_bias\n",
                "self_attn_out_proj_weight = decoder_layer_torch.self_attn.out_proj.weight\n",
                "self_attn_out_proj_bias = decoder_layer_torch.self_attn.out_proj.bias\n",
                "\n",
                "cross_attn_in_proj_weight = decoder_layer_torch.multihead_attn.in_proj_weight\n",
                "cross_attn_in_proj_bias = decoder_layer_torch.multihead_attn.in_proj_bias\n",
                "cross_attn_out_proj_weight = decoder_layer_torch.multihead_attn.out_proj.weight\n",
                "cross_attn_out_proj_bias = decoder_layer_torch.multihead_attn.out_proj.bias\n",
                "\n",
                "linear1_weight = decoder_layer_torch.linear1.weight\n",
                "linear1_bias = decoder_layer_torch.linear1.bias\n",
                "linear2_weight = decoder_layer_torch.linear2.weight\n",
                "linear2_bias = decoder_layer_torch.linear2.bias\n",
                "norm1_weight = decoder_layer_torch.norm1.weight\n",
                "norm1_bias = decoder_layer_torch.norm1.bias\n",
                "norm2_weight = decoder_layer_torch.norm2.weight\n",
                "norm2_bias = decoder_layer_torch.norm2.bias\n",
                "norm3_weight = decoder_layer_torch.norm3.weight\n",
                "norm3_bias = decoder_layer_torch.norm3.bias"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 手动实现"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": [
                "def transformer_decoder_layer_fwd(\n",
                "    tgt,\n",
                "    memory,\n",
                "    nhead,\n",
                "    self_attn_in_proj_weight,\n",
                "    self_attn_in_proj_bias,\n",
                "    self_attn_out_proj_weight,\n",
                "    self_attn_out_proj_bias,\n",
                "    cross_attn_in_proj_weight,\n",
                "    cross_attn_in_proj_bias,\n",
                "    cross_attn_out_proj_weight,\n",
                "    cross_attn_out_proj_bias,\n",
                "    linear1_weight,\n",
                "    linear1_bias,\n",
                "    linear2_weight,\n",
                "    linear2_bias,\n",
                "    norm1_weight,\n",
                "    norm1_bias,\n",
                "    norm2_weight,\n",
                "    norm2_bias,\n",
                "    norm3_weight,\n",
                "    norm3_bias,\n",
                "    dropout_p=0,\n",
                "    layer_norm_eps=1e-5,\n",
                "    tgt_mask=None,\n",
                "    memory_mask=None,\n",
                "    tgt_key_padding_mask=None,\n",
                "    memory_key_padding_mask=None,\n",
                "):\n",
                "    norm1 = F.layer_norm(\n",
                "        tgt, (tgt.size(-1),), norm1_weight, norm1_bias, eps=layer_norm_eps\n",
                "    )\n",
                "    out1 = multihead_attn(\n",
                "        norm1,\n",
                "        norm1,\n",
                "        norm1,\n",
                "        nhead,\n",
                "        self_attn_in_proj_weight,\n",
                "        self_attn_in_proj_bias,\n",
                "        self_attn_out_proj_weight,\n",
                "        self_attn_out_proj_bias,\n",
                "        dropout_p,\n",
                "        key_padding_mask=tgt_key_padding_mask,\n",
                "        attn_mask=tgt_mask,\n",
                "        need_weights=False,\n",
                "    )\n",
                "    out1 += tgt\n",
                "\n",
                "    norm2 = F.layer_norm(\n",
                "        out1, (out1.size(-1),), norm2_weight, norm2_bias, eps=layer_norm_eps\n",
                "    )\n",
                "    out2 = multihead_attn(\n",
                "        norm2,\n",
                "        memory,\n",
                "        memory,\n",
                "        nhead,\n",
                "        cross_attn_in_proj_weight,\n",
                "        cross_attn_in_proj_bias,\n",
                "        cross_attn_out_proj_weight,\n",
                "        cross_attn_out_proj_bias,\n",
                "        dropout_p,\n",
                "        key_padding_mask=memory_key_padding_mask,\n",
                "        attn_mask=memory_mask,\n",
                "        need_weights=False,\n",
                "    )\n",
                "    out2 += out1\n",
                "\n",
                "    norm3 = F.layer_norm(\n",
                "        out2, (out2.size(-1),), norm3_weight, norm3_bias, eps=layer_norm_eps\n",
                "    )\n",
                "\n",
                "    out3 = (\n",
                "        feedforward_block(\n",
                "            norm3, linear1_weight, linear1_bias, linear2_weight, linear2_bias, dropout_p\n",
                "        )\n",
                "        + out2\n",
                "    )\n",
                "    return out3"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "decoder_output = transformer_decoder_layer_fwd(\n",
                "    tgt_input_tensor,\n",
                "    encoder_memory,\n",
                "    nhead,\n",
                "    self_attn_in_proj_weight,\n",
                "    self_attn_in_proj_bias,\n",
                "    self_attn_out_proj_weight,\n",
                "    self_attn_out_proj_bias,\n",
                "    cross_attn_in_proj_weight,\n",
                "    cross_attn_in_proj_bias,\n",
                "    cross_attn_out_proj_weight,\n",
                "    cross_attn_out_proj_bias,\n",
                "    linear1_weight,\n",
                "    linear1_bias,\n",
                "    linear2_weight,\n",
                "    linear2_bias,\n",
                "    norm1_weight,\n",
                "    norm1_bias,\n",
                "    norm2_weight,\n",
                "    norm2_bias,\n",
                "    norm3_weight,\n",
                "    norm3_bias,\n",
                "    dropout_p=dropout,\n",
                "    tgt_mask=tgt_mask,\n",
                "    memory_mask=None,\n",
                "    tgt_key_padding_mask=tgt_padding_mask,\n",
                "    memory_key_padding_mask=src_padding_mask,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "decoder_layer_output: ✅\n"
                    ]
                }
            ],
            "source": [
                "compare_output(\"decoder_layer_output\", decoder_output_torch, decoder_output, atol=1e-6)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Decoder 损失函数"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor(10.9175, grad_fn=<NllLoss2DBackward0>)\n"
                    ]
                }
            ],
            "source": [
                "max_tgt_seqlen = max(tgt_seq_len)\n",
                "\n",
                "# 先将 decoder 的输出经过一个分类头进行变换\n",
                "decoder_head = nn.Linear(d_model, vocab_size)\n",
                "logits = decoder_head(decoder_output)  # [batch_size, seqlen, vocab_size]\n",
                "\n",
                "# 生成真实标签，使用-100进行 batch 内的填充，计算损失时会自动忽略\n",
                "labels = torch.stack(\n",
                "    [\n",
                "        F.pad(\n",
                "            torch.randint(0, vocab_size, (seqlen,)),\n",
                "            (0, max_tgt_seqlen - seqlen),\n",
                "            value=-100,\n",
                "        )\n",
                "        for seqlen in tgt_seq_len\n",
                "    ],\n",
                "    dim=0,\n",
                ")\n",
                "\n",
                "decoder_loss = F.cross_entropy(\n",
                "    logits.transpose(1, 2), labels, ignore_index=-100, reduction=\"mean\"\n",
                ")\n",
                "print(decoder_loss)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 自回归生成\n",
                "\n",
                "每一步推理预测一个字符，然后将该预测的字符和 decoder 的输入拼在一起后再次作为输入。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [],
            "source": [
                "encoder_layer = nn.TransformerEncoderLayer(\n",
                "    d_model,\n",
                "    nhead,\n",
                "    dim_feedforward,\n",
                "    dropout,\n",
                "    batch_first=batch_first,\n",
                "    norm_first=norm_first,\n",
                ")\n",
                "encoder = nn.TransformerEncoder(\n",
                "    encoder_layer=encoder_layer,\n",
                "    num_layers=num_encoder_layers,\n",
                "    enable_nested_tensor=False,\n",
                ")\n",
                "\n",
                "decoder_layer = nn.TransformerDecoderLayer(\n",
                "    d_model,\n",
                "    nhead,\n",
                "    dim_feedforward,\n",
                "    dropout,\n",
                "    batch_first=batch_first,\n",
                "    norm_first=norm_first,\n",
                ")\n",
                "\n",
                "decoder = nn.TransformerDecoder(\n",
                "    decoder_layer=decoder_layer,\n",
                "    num_layers=num_decoder_layers,\n",
                ")\n",
                "decoder_head = nn.Linear(d_model, vocab_size)\n",
                "token_embedding = nn.Embedding(vocab_size, d_model)\n",
                "\n",
                "src_seqlen = 10\n",
                "src_ids = torch.randint(0, vocab_size, (src_seqlen,))\n",
                "tgt_ids = torch.LongTensor([0])  # <bos>\n",
                "\n",
                "input_embeddings = token_embedding(src_ids)\n",
                "memory = encoder(input_embeddings)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor([    0,  4474,  5914,  3152,  5914, 10405])\n"
                    ]
                }
            ],
            "source": [
                "decoder_steps = 5\n",
                "for _ in range(decoder_steps):\n",
                "    tgt_embeddings = token_embedding(tgt_ids)\n",
                "    decode_output = decoder(tgt_embeddings, memory)\n",
                "    logits = decoder_head(decode_output)[-1, :][None, :]\n",
                "    next_token_id = torch.argmax(logits, -1)\n",
                "    tgt_ids = torch.concat([tgt_ids, next_token_id], dim=-1)\n",
                "print(tgt_ids)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "pyml",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
