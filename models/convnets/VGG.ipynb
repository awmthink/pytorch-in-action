{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 用于大规模图像识别的超深卷积网络（2014）\n",
                "\n",
                "VGG架构由牛津大学视觉几何组的Karen Simonyan和Andrew Zisserman于2014年开发，因此被命名为VGG。该模型在当时显著优于之前的模型，特别是在2014年的Imagenet挑战赛中，也称为ILSVRC。\n",
                "\n",
                "论文地址：https://arxiv.org/abs/1409.1556\n",
                "\n",
                "<div class=\"alert alert-info\">\n",
                "**摘要**：wy-nav-content-img其在大规模图像识别设置中的准确性的影响。我们的主要贡献是对使用非常小的（3x3）卷积滤波器的网络进行彻底评估，这表明通过将深度推进到 16-19 个权重层，可以在先前的配置上实现显著的改进。这些发现是我们 2014 年 ImageNet 挑战赛提交的基础，我们的团队分别在定位和分类赛道上获得了第一和第二名。我们还表明，我们的模型在其它数据集上具有良好的泛化能力，并取得了最先进的结果。我们已经将我们表现最好的两个 ConvNet 模型公开，以促进对计算机视觉中深度视觉表示使用的进一步研究。\n",
                "</div>\n",
                "\n",
                "\n",
                "## VGG网络架构\n",
                "\n",
                "<div class=\"wy-nav-content-img\">\n",
                "    <img src=\"./assets/VGG_vgg_arch.png\" alt=\"VGG 的架构图\">\n",
                "    <p>图1: VGG 的架构图</p>\n",
                "</div>\n",
                "\n",
                "从上图中可以看出，VGG 的整体结构是由 5 个 卷积块和 3 层全连接构成的。每个卷积块是由若干的卷积层、非线性激活层、归一化层、最大池化层组成。每一个卷积块都会在第一个 Conv2d 进行特征通道的加倍 (最后一个 ConvBlock 没有改变通道数)，然后最后加一个 MaxPooling 将 FeatureMap 的分辨率减半。\n",
                "\n",
                "* 输入为 `224x224` 的图像。\n",
                "* 卷积核的形wy-nav-content-img状为 `(2,2)`。\n",
                "* 每个卷积层的通道数量为 `64 -> 128 -> 256 -> 512 -> 512`。\n",
                "* VGG16 具有 16 个隐藏层（13个卷积层和3个全连接层）。\n",
                "* VGG19 具有 19 个隐藏层（16个卷积层和3个全连接层）。\n",
                "\n",
                "\n",
                "<div class=\"wy-nav-content-img\">\n",
                "    <img src=\"./assets/VGG_vgg_configuration.png\" width=600px alt=\"VGG Configuration\">\n",
                "    <p>不同层数的 VGG 模型的架构配置</p>\n",
                "</div>\n",
                "\n",
                "## 关键比较\n",
                "\n",
                "* VGG（16或19层）相比当时的其他 SOTA 网络相对更深。例如，2012年ILSVRC的获胜模型 AlexNet 仅有8层。\n",
                "* 采用多个小（3x3）感受野的卷积滤波器并配合ReLU激活函数，而不是一个大的（7x7或11x11）滤波器，能够更好地学习复杂特征。较小的滤波器还意味着每层的参数更少，同时在层间引入了额外的非线性。\n",
                "* 多尺度训练和推理。每张图像在多个不同尺度下训练多轮，以确保不同大小的图像具有相似的特征。\n",
                "* VGG网络的一致性和简洁性使其更易于扩展或进行未来改进。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## VGG 的模型实现"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "from typing import List\n",
                "\n",
                "\n",
                "class VGG(nn.Module):\n",
                "    def __init__(\n",
                "        self,\n",
                "        config,\n",
                "        in_chans=3,\n",
                "        num_classes=1000,\n",
                "        act_layer=nn.ReLU,\n",
                "        norm_layer=None,\n",
                "        pool_layer=nn.MaxPool2d,\n",
                "    ):\n",
                "        super().__init__()\n",
                "\n",
                "        prev_chs = in_chans\n",
                "        layers: List[nn.Module] = []\n",
                "        for v in config:\n",
                "            if v == \"M\":\n",
                "                # \"M\" 代表当前层是 MaxPooling 层\n",
                "                layers += [pool_layer(kernel_size=2, stride=2)]\n",
                "            else:\n",
                "                # conv -> bn -> relu or conv -> relu\n",
                "                conv2d = nn.Conv2d(prev_chs, v, kernel_size=3, padding=1)\n",
                "                if norm_layer is not None:\n",
                "                    layers += [conv2d, norm_layer(v), act_layer(inplace=True)]\n",
                "                else:\n",
                "                    layers += [conv2d, act_layer(inplace=True)]\n",
                "                prev_chs = v\n",
                "\n",
                "        # 特征提取层：卷积和池化层\n",
                "        self.feature_extractor = nn.Sequential(*layers)\n",
                "\n",
                "        # 池化层，自适应的把 featrue extractor 出来的 featuremap 缩放到 7x7 的大小\n",
                "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(7, 7))\n",
                "\n",
                "        # 用于分类的全连接层\n",
                "        self.classifier = nn.Sequential(\n",
                "            nn.Linear(512 * 7 * 7, 4096),  # 512通道，最大池化后的空间维度为7x7\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(0.5),  # Dropout层，概率为0.5\n",
                "            nn.Linear(4096, 4096),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(0.5),\n",
                "            nn.Linear(4096, num_classes),  # 输出层，具有'num_classes'个输出单元\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.feature_extractor(x)  # 通过特征提取层\n",
                "        x = self.avgpool(x)  # 通过池化层\n",
                "        x = x.view(x.size(0), -1)  # 将输出展平以传递到全连接层\n",
                "        x = self.classifier(x)  # 通过分类层\n",
                "        return x"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "output shape of vgg model (w/o BatchNorm) : torch.Size([1, 1000])\n",
                        "output shape of vgg model with BatchNorm : torch.Size([1, 1000])\n"
                    ]
                }
            ],
            "source": [
                "vgg19_configuration = [\n",
                "    64,\n",
                "    64,\n",
                "    \"M\",\n",
                "    128,\n",
                "    128,\n",
                "    \"M\",\n",
                "    256,\n",
                "    256,\n",
                "    256,\n",
                "    256,\n",
                "    \"M\",\n",
                "    512,\n",
                "    512,\n",
                "    512,\n",
                "    512,\n",
                "    \"M\",\n",
                "    512,\n",
                "    512,\n",
                "    512,\n",
                "    512,\n",
                "    \"M\",\n",
                "]\n",
                "model = VGG(vgg19_configuration)\n",
                "\n",
                "model_with_bn = VGG(vgg19_configuration, norm_layer=nn.BatchNorm2d)\n",
                "\n",
                "x = torch.randn(1, 3, 224, 224)\n",
                "out = model(x)\n",
                "print(f\"output shape of vgg model (w/o BatchNorm) : {out.shape}\")\n",
                "\n",
                "out1 = model_with_bn(x)\n",
                "print(f\"output shape of vgg model with BatchNorm : {out1.shape}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "pyml",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}